{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"momentum\": 0.9,\n",
    "    \"acc\": 0.0,\n",
    "    \"epoca\": 0,\n",
    "    \"input_file\": '/data/concentlite.csv',\n",
    "    \"EXP_NAME\": 'EXP009',\n",
    "    \"MIN_ACC\": 1.0,\n",
    "    \"MIN_ERROR\": 1E6,\n",
    "    \"MAX_EPOCAS\": 1000,\n",
    "    \"MAX_COUNTER\": 50,\n",
    "    \"BATCH_SIZE\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "# NN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# RBF source model -----------------------\n",
    "from src import torch_rbf as rbf\n",
    "#from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "## Ploting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "from matplotlib.colors import to_rgba\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "# Path\n",
    "import sys\n",
    "sys.path.append('/home/sebacastillo/neuralnets/')\n",
    "from src.utils import get_project_root\n",
    "root = get_project_root()\n",
    "## Check torch version\n",
    "print(f'Using {torch.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else torch.device('cpu'))\n",
    "torch.manual_seed(42)\n",
    "# GPU operations have a separate seed we also want to set\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
    "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_save_data(input_filename, output_name='EXP', split_type='train_test', train_ratio=0.75, validate_ratio=None, test_ratio=None):\n",
    "\n",
    "    data = pd.read_csv(input_filename)\n",
    "\n",
    "    # Check if 'exp' folder exists, create it if it doesn't\n",
    "    if not os.path.exists('exp'):\n",
    "        os.makedirs('exp')\n",
    "    \n",
    "    # Create a subfolder with the output_name\n",
    "    output_path = os.path.join('exp', output_name)\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        \n",
    "    if split_type == 'train_validate_test':\n",
    "        if not validate_ratio or not test_ratio:\n",
    "            raise ValueError(\"Please provide validate_ratio and test_ratio for 'train_validate_test' split type.\")\n",
    "        \n",
    "        train_data, temp_data = train_test_split(data, train_size=train_ratio, random_state=42)\n",
    "        validate_data, test_data = train_test_split(temp_data, train_size=validate_ratio / (validate_ratio + test_ratio), random_state=42)\n",
    "        \n",
    "        # Save the train, validate, and test data as CSV files in the output folder\n",
    "        train_data.to_csv(os.path.join(output_path, f'{output_name}_train_data.csv'), index=False)\n",
    "        validate_data.to_csv(os.path.join(output_path, f'{output_name}_validate_data.csv'), index=False)\n",
    "        test_data.to_csv(os.path.join(output_path, f'{output_name}_test_data.csv'), index=False)\n",
    "\n",
    "\n",
    "        return train_data, validate_data, test_data    \n",
    "\n",
    "    elif split_type == 'train_test':\n",
    "        train_data, test_data = train_test_split(data, train_size=train_ratio, random_state=42)\n",
    "        \n",
    "        # Save the train and test data as CSV files in the output folder\n",
    "        train_data.to_csv(os.path.join(output_path, f'{output_name}_train_data.csv'), index=False)\n",
    "        test_data.to_csv(os.path.join(output_path, f'{output_name}_test_data.csv'), index=False)\n",
    "\n",
    "\n",
    "        return train_data, test_data\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Invalid split_type. Use either 'train_validate_test' or 'train_test'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATASET(Dataset):  \n",
    "    '''\n",
    "    Esta clase maneja la lectura de los datos y provee un mecanismo\n",
    "    para alimentar los modelos con los patrones.\n",
    "    '''\n",
    "    \n",
    "    #===================================================\n",
    "    def __init__(self, filename):\n",
    "        \n",
    "        #------------------------------------\n",
    "        # LECTURA DE LOS DATOS\n",
    "        data = pd.read_csv(filename, header=None).to_numpy() # Levanta los datos en formato numpy\n",
    "        \n",
    "        #------------------------------------\n",
    "        # INSERTAMOS COLUMNA DEL \"BIAS\"\n",
    "        #bias = -np.ones((len(data), 1))\n",
    "        #data = np.concatenate((bias, data), axis=1)  # Insertamos el \"bias\" en la primera columna\n",
    "        \n",
    "        #------------------------------------\n",
    "        # ALEATORIZO LOS PATRONES (filas)\n",
    "        idxs = np.arange(len(data))  # Genero un vector de índices\n",
    "        np.random.shuffle(idxs)\n",
    "        data = data[idxs,:]\n",
    "        \n",
    "        #------------------------------------\n",
    "        # SEPARO LOS DATOS\n",
    "        self.x = data[:,:-1].astype(np.float32)\n",
    "        self.y = data[:,-1].astype(np.float32)  # La clase está en la última columna\n",
    "    \n",
    "    #===================================================\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Devuelve el número de patrones en el dataset.\n",
    "        '''\n",
    "        return len(self.x)\n",
    "    \n",
    "    \n",
    "    #===================================================\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Devuelve el/los patrones indicados.\n",
    "        '''\n",
    "        return self.x[idx,:], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_with_labels(data):\n",
    "    # Filter data by label\n",
    "    data_label_1 = data[data[:, -1] == 1][:, 0:2]\n",
    "    data_label_minus_1 = data[data[:, -1] == -1][:, 0:2]\n",
    "\n",
    "    # Create scatter plots for each label\n",
    "    plt.scatter(data_label_1[:, 0], data_label_1[:, 1], label='1', alpha=0.5)\n",
    "    plt.scatter(data_label_minus_1[:, 0], data_label_minus_1[:, 1], label='-1', alpha=0.5)\n",
    "\n",
    "    plt.xlabel('Feature 1')\n",
    "    plt.ylabel('Feature 2')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1: NN + RBFLayer \n",
    "\n",
    "- source: https://github.com/rssalessio/PytorchRBFLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.size(0)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        return (x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer_widths, layer_centres, basis_func):\n",
    "        super(Network, self).__init__()\n",
    "        self.rbf_layers = nn.ModuleList()\n",
    "        self.linear_layers = nn.ModuleList()\n",
    "        for i in range(len(layer_widths) - 1):\n",
    "            self.rbf_layers.append(rbf.RBF(layer_widths[i], layer_centres[i], basis_func))\n",
    "            self.linear_layers.append(nn.Linear(layer_centres[i], layer_widths[i+1]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for i in range(len(self.rbf_layers)):\n",
    "            out = self.rbf_layers[i](out)\n",
    "            out = self.linear_layers[i](out)\n",
    "        return out\n",
    "    \n",
    "    def fit(self, x, y, epochs, batch_size, lr, loss_func):\n",
    "        self.train()\n",
    "        obs = x.size(0)\n",
    "        trainset = MyDataset(x, y)\n",
    "        trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "        optimiser = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        epoch = 0         \n",
    "        accuracy = []  \n",
    "        while epoch < epochs:\n",
    "            epoch += 1\n",
    "            current_loss = 0\n",
    "            batches = 0\n",
    "            progress = 0\n",
    "            correct_predictions = 0\n",
    "            for x_batch, y_batch in trainloader:\n",
    "                batches += 1\n",
    "                optimiser.zero_grad()\n",
    "                y_hat = self.forward(x_batch)\n",
    "                loss = loss_func(y_hat, y_batch)\n",
    "                current_loss += (1/batches) * (loss.item() - current_loss)            \n",
    "                # Calculate accuracy\n",
    "                pred = torch.sign(y_hat)  # Get predictions as either -1 or 1\n",
    "                correct_predictions += (pred == y_batch).sum().item()\n",
    "\n",
    "                loss.backward()\n",
    "                optimiser.step()\n",
    "                progress += y_batch.size(0)\n",
    "                sys.stdout.write('\\rEpoch: %d, Progress: %d/%d, Loss: %f, Accuracy: %f      ' % \\\n",
    "                                (epoch, progress, obs, current_loss, correct_predictions / progress))\n",
    "                sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment\n",
    "x1 = np.linspace(-1, 1, 101)\n",
    "x2 = 0.5*np.cos(np.pi*x1) + 0.5*np.cos(4*np.pi*(x1+1)) # <- decision boundary\n",
    "\n",
    "samples = 200\n",
    "x = np.random.uniform(-1, 1, (samples, 2))\n",
    "for i in range(samples):\n",
    "    if i < samples//2:\n",
    "        x[i,1] = np.random.uniform(-1, 0.5*np.cos(np.pi*x[i,0]) + 0.5*np.cos(4*np.pi*(x[i,0]+1)))\n",
    "    else:\n",
    "        x[i,1] = np.random.uniform(0.5*np.cos(np.pi*x[i,0]) + 0.5*np.cos(4*np.pi*(x[i,0]+1)), 1)\n",
    "\n",
    "steps = 100\n",
    "x_span = np.linspace(-1, 1, steps)\n",
    "y_span = np.linspace(-1, 1, steps)\n",
    "xx, yy = np.meshgrid(x_span, y_span)\n",
    "values = np.append(xx.ravel().reshape(xx.ravel().shape[0], 1),\n",
    "                   yy.ravel().reshape(yy.ravel().shape[0], 1),\n",
    "                   axis=1)\n",
    "\n",
    "tx = torch.from_numpy(x).float()\n",
    "ty = torch.cat((torch.zeros(samples//2,1), torch.ones(samples//2,1)), dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename_train_data = str(root) + '/data/XOR_trn.csv'\n",
    "filename_train_data = str(root) + '/data/concentlite.csv'\n",
    "filename_validation_data = str(root) +'/data/XOR_tst.csv'\n",
    "train = pd.read_csv(filename_train_data, header=None).to_numpy() # Levanta los datos en formato numpy\n",
    "test = pd.read_csv(filename_train_data, header=None).to_numpy() # Levanta los datos en formato numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([833, 2]), torch.Size([833, 1]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train[:,:-1]\n",
    "y = train[:,-1]\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y).float()\n",
    "y = y.unsqueeze(1)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, Progress: 833/833, Loss: 0.234270, Accuracy: 0.969988      "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (rbf_layers): ModuleList(\n",
       "    (0): RBF()\n",
       "  )\n",
       "  (linear_layers): ModuleList(\n",
       "    (0): Linear(in_features=10, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instanciating and training an RBF network with the Gaussian basis function\n",
    "# This network receives a 2-dimensional input, transforms it into a 40-dimensional\n",
    "# hidden representation with an RBF layer and then transforms that into a\n",
    "# 1-dimensional output/prediction with a linear layer\n",
    "\n",
    "# To add more layers, change the layer_widths and layer_centres lists\n",
    "\n",
    "layer_widths = [2, 1]\n",
    "layer_centres = [10]\n",
    "basis_func = rbf.gaussian\n",
    "batch_size = 300\n",
    "\n",
    "\n",
    "rbfnet = Network(layer_widths, layer_centres, basis_func)\n",
    "rbfnet.fit(X, y, 1000, batch_size, 0.001, nn.MSELoss(reduction='mean'))\n",
    "rbfnet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model2: RBFNet-Simple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class RBFNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_centers, sigma):\n",
    "        super(RBFNet, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_centers = num_centers\n",
    "        \n",
    "        self.centers = nn.Parameter(torch.randn(num_centers, input_dim))\n",
    "        self.beta = nn.Parameter(torch.ones(num_centers, 1) / num_centers)\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        self.fc = nn.Linear(num_centers, output_dim)\n",
    "    \n",
    "    def radial_basis(self, x):\n",
    "        C = self.centers.view(self.num_centers, -1)\n",
    "        x = x.unsqueeze(1).expand(-1, self.num_centers, -1)\n",
    "        return torch.exp(-torch.sum((x - C) ** 2, dim=2) / (2 * self.sigma ** 2))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1)\n",
    "        H = self.radial_basis(x)\n",
    "        out = self.fc(H)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0059, -0.1851], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 10\n",
    "hidden_dim = 100\n",
    "output_dim = 2\n",
    "num_centers = 20\n",
    "sigma = 1.0\n",
    "\n",
    "model = RBFNet(input_dim, hidden_dim, output_dim, num_centers, sigma)\n",
    "\n",
    "x = torch.randn(32, input_dim)\n",
    "output = model(x)\n",
    "output[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".neuralnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
