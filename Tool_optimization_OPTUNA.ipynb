{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example with **AX**: https://pytorch.org/tutorials/intermediate/ax_multiobjective_nas_tutorial.html\n",
    "- Example with **Optuna**: https://github.com/optuna/optuna-examples/blob/main/pytorch/pytorch_simple.py\n",
    "  - notebook1: https://github.com/marcellusruben/medium-resources/blob/main/Optuna/Optuna.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# Visualization\n",
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-09 20:12:19,511]\u001b[0m A new study created in RDB with name: mnist\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\", \n",
    "    storage=\"sqlite:///db.sqlite3\",  # Specify the storage URL here.\n",
    "    study_name=\"mnist\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-09 20:12:51,510]\u001b[0m Trial 0 finished with value: 0.0921875 and parameters: {'n_layers': 2, 'n_units_l0': 19, 'dropout_l0': 0.4695922979051355, 'n_units_l1': 19, 'dropout_l1': 0.3844412020198067, 'optimizer': 'SGD', 'lr': 0.00014425559433537405}. Best is trial 0 with value: 0.0921875.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 20:13:00,309]\u001b[0m Trial 1 finished with value: 0.7265625 and parameters: {'n_layers': 1, 'n_units_l0': 15, 'dropout_l0': 0.45241986695335873, 'optimizer': 'RMSprop', 'lr': 0.004147143605174518}. Best is trial 1 with value: 0.7265625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 20:13:09,108]\u001b[0m Trial 2 finished with value: 0.7578125 and parameters: {'n_layers': 1, 'n_units_l0': 107, 'dropout_l0': 0.2480036016557838, 'optimizer': 'RMSprop', 'lr': 0.017405135925527674}. Best is trial 2 with value: 0.7578125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 20:13:18,340]\u001b[0m Trial 3 finished with value: 0.61484375 and parameters: {'n_layers': 3, 'n_units_l0': 12, 'dropout_l0': 0.44481062924036485, 'n_units_l1': 86, 'dropout_l1': 0.2832304005407628, 'n_units_l2': 64, 'dropout_l2': 0.2892263210471403, 'optimizer': 'Adam', 'lr': 0.00858494817088209}. Best is trial 2 with value: 0.7578125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 20:13:26,743]\u001b[0m Trial 4 finished with value: 0.128125 and parameters: {'n_layers': 1, 'n_units_l0': 25, 'dropout_l0': 0.22377021355868745, 'optimizer': 'SGD', 'lr': 1.9553846394705205e-05}. Best is trial 2 with value: 0.7578125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-09 20:13:28,781]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-09 20:13:30,922]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-09 20:13:32,953]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-09 20:13:35,556]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-09 20:13:37,645]\u001b[0m Trial 9 pruned. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=10, timeout=600)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  60\n",
      "  Number of pruned trials:  36\n",
      "  Number of complete trials:  24\n"
     ]
    }
   ],
   "source": [
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value:  0.85234375\n",
      "  Params: \n",
      "    n_layers: 1\n",
      "    n_units_l0: 115\n",
      "    dropout_l0: 0.30686750726727063\n",
      "    optimizer: Adam\n",
      "    lr: 0.0043727807057160435\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour(study)\n",
    "# plot_contour(study, params=[\"bagging_freq\", \"bagging_fraction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_param_importances(study)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn which hyperparameters are affecting the trial duration with hyperparameter importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(\n",
    "    study, target=lambda t: t.duration.total_seconds(), target_name=\"duration\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminal run:\n",
    "\n",
    "'optuna-dashboard sqlite:///db.sqlite3'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".neuralnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
